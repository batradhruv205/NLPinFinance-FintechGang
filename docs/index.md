Excuse the name - this was a school project and we were forced to choose 'cool' names for our groups. This task was done as a class project for a course on Natural Language Processing for Finance. 

The project was quite open-ended and left to us students to figure out. For us finance students, the first thing on our minds is always the stock market. And so, we felt that the project had to be somehow related to the stock market. But, we did not want to simply run a sentiment analysis on Trump's tweets and look at stock movements - we wanted to do something slightly off the usual.

Our project was focused on looking at a very common topic within finance – Earnings Releases. The usual analysis in this area is the semantic analysis of speeches and statements of senior executives of a firm to predict the said firm's upcoming earnings. We chose to leave this part to individual investors, and instead, analyze opinions of investors on certain social media platforms. The underlying idea was that markets are mostly efficient in the manner that publicly available information is consumed by individual investors without much time-lag. Consequently, the combined view of all investors should be a good indicator of the agregate market prediction. The proxy for investor opinions were chosen to be posts on Twitter, StockTwits, and Reddit regarding the firms' performance. 

Such a study implied the potential removal of the need for an investor to collect a large number of sources that may provide insights into the earnings releases of a firm. It restricted information sources to just a few and in a manner, crowd-sourced information. 

The focus of the project was on predicting earnings __surprises__ – the over or underperformance as compared to market expectation – using textual data from Twitter, StockTwits and Reddit. 

Below are two blogs our team wrote towards the later part of the project. Check them out!

## What we thought – 

The key idea behind this project was to make easy money, investigate Earnings Releases, and try to find some insights from textual data that surround these Releases. When companies publish their finances, markets react according to the results of their investments’ accounts. While it would be great to be able to buy or sell in markets right after getting your hands on these published reports, earnings are usually released after market hours, disallowing investors to make a profit from them. Consequently, we wanted to explore whether we could identify any leading indicators of how a company’s report card would turn out.
There is a plethora of information available in the public knowledge sphere that supposedly makes markets efficient and could possibly be very good indicators of what investors should be expecting from earnings calls. Given this, markets already have an established expectation of companies’ accounting numbers that are readily available on several sources such as Yahoo! Finance (different outlets have their own methods of calculating this). Further, these expectations are already priced into the market long before the numbers are published. Therefore, the only opportunity of profiting out of this situation is to be able to predict surprises in these earnings.

While we could dig through the aforementioned information sources such as news articles, interviews of top management, investor reports etc., we chose to take a different (and hopefully shorter) route. Instead of crunching through publicly available data ourselves, we let people do that and attempted to find out what people have been thinking about. We believe that humans would be able to capture and process all possible information, build an opinion of their own and then take to social media to write about it. We hoped that the aggregate sentiment of the masses would accurately reflect all available information. The below chart explains this idea.
 
We chose to look at 3 popular social media sources – Twitter, StockTwits and Reddit. We chose Twitter because it is where “everybody is”, StockTwits because it is where “investors are” and Reddit because it is where users have a “superiority complex” about their knowledge and intellect. We felt that these three platforms would give us a complete picture of what investors believe about the performance of these companies and could possibly be the goldmine for predicting earnings surprises. What did we find? Check out our next blog to find out!


## Reflection on our project journey 

This blog is written to document our reflection on what we have observed and learnt so far. We will share some difficulties we encounter and our takeaways from them. 
As we have discussed in our first presentation, the first step of our project is data collection. We located 3 different sources for getting our textual data, namely Reddit, Twitter and Stocktwits and Yahoo Finance for obtaining all earnings release. 

For getting earning scores from Yahoo, there is a Yahoo Earnings Calendar Scraper available on Github, we modified the code and successfully extract the desired data. It went super smooth. 
Let's talk about Reddit! There are several concerns with reddit data – firstly, there isn’t enough data! Seemingly, investors of the world don’t prefer Reddit as much as we believed them to. This leads to the lack of data in general for each company and earnings release pair. Secondly, unlike most other subreddits, r/investing does not have a very standardized set of acronyms and writing styles. This means that different users write about things in different ways, making text analytics slightly tougher. Third, following on from the previous issue, there is no one way to mention a specific company/stock. Some users will write the full name of the company, some will use the ticker and some will use an alternative short name. This makes the search functionality less effective than desired. Finally, reddit submissions come with upvotes, downvotes and comments. This means that the actual impact and correctness of a submission can be well judged by the amount of (good) attention that it gets. However, going back to the first issue, there aren’t enough people commenting or voting on posts which leaves us with all posts weighted equally. The key idea here is that selection of sources is very important for any sort of analysis. While Reddit can be a great source of textual data for many other purposes, it is probably not the best one for financial opinions. The biggest issue with reddit is just the lack of audience and users. However, Reddit does provide a lot of potential for text analysis given its very user-friendly API and a massive amount of data. 

Then for Stocktwits, it probably has the best textual data for financial analysis, in terms of, quantity, quality and relevancy. However, obtaining the data is a really painful process. The first and biggest roadblock is that Stocktwits doesn't allow web scraping and its API has a rate limit that only provides minimum amount of data, which can not be used for NLP and text analytics. Although we are a bunch of business students with limited tech background, this technical difficulty didn't scare us away as we have a philosophy that every problem can be solve by a line of code, if not, then go to Github. 
As our philosophy predicts, there is a solution on GitHub. We modified the established code for our project and we manage to get over the API rate limit, without knowing what exactly the code does and the complex programming knowledge behind. This doesn't mean programming knowledge is not important, but rather, this resonates with our course focus - application, or being able to use existing building blocks to design a something. For Twitter, we encountered the same thing and used the same solution. Our own coding skills were actually improved through reading and analyzing other people's established code. 
For data processing, things became a little bit easier. Our main challenge here is how to deal with the discrepancy between theory and practical applications. Even though we are provided with complete examples in lecture notes but in reality when we are doing text preprocessing we do have to decide whether a particular type of text poses meaning to our analysis. For example, we decided to remove the links and the symbols of the tickers in addition to the conventional methods looking at their high frequency of occurrences in our textual data. It is about how to make good use of what we learn from the lectures in a constructive way. 

Now all data is ready for running the model, we will follow along the lecture notes and let's see what will turn out. 

### [Click here to check out my group's final report!](docs/Documents/FinalReport.pdf)
